{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [

  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# ðŸ›’ UK Retail Purchase Prediction â€” MLOps Level 0â€“2\n",
    "\n",
    "**Dataset:** Online Retail II (UK only)  \n",
    "**Model:** XGBoost Binary Classifier  \n",
    "**Goal:** Predict if a customer will purchase next month  \n",
    "\n",
    "---\n",
    "### Pipeline\n",
    "```\n",
    "Raw CSV â†’ Preprocessing â†’ Feature Engineering â†’ Target Creation\n",
    "       â†’ Train/Test Split â†’ XGBoost Training â†’ Evaluation\n",
    "       â†’ Model Saving â†’ Drift Monitoring\n",
    "```"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-imports",
   "metadata": {},
   "source": ["## 1ï¸âƒ£ Imports & Setup"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print('âœ… Libraries loaded')\n",
    "print(f'   pandas  {pd.__version__}')\n",
    "print(f'   numpy   {np.__version__}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-load",
   "metadata": {},
   "source": ["## 2ï¸âƒ£ Load Raw Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ Update path to your downloaded Online Retail II CSV\n",
    "RAW_PATH = 'data/raw.csv'\n",
    "\n",
    "df = pd.read_csv(RAW_PATH, encoding='ISO-8859-1')\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Dataset Info ===')\n",
    "df.info()\n",
    "print('\\n=== Null counts ===')\n",
    "print(df.isnull().sum())\n",
    "print('\\n=== Countries ===')\n",
    "print(df['Country'].value_counts().head(10))"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-clean",
   "metadata": {},
   "source": ["## 3ï¸âƒ£ Data Cleaning & Filtering"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to UK only\n",
    "df_uk = df[df['Country'] == 'United Kingdom'].copy()\n",
    "print(f'UK records: {len(df_uk):,}')\n",
    "\n",
    "# Drop nulls\n",
    "df_uk.dropna(subset=['Customer ID'], inplace=True)\n",
    "\n",
    "# Remove cancellations and invalid rows\n",
    "df_uk = df_uk[df_uk['Quantity'] > 0]\n",
    "df_uk = df_uk[df_uk['Price'] > 0]\n",
    "\n",
    "print(f'After cleaning: {df_uk.shape}')\n",
    "df_uk.describe()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-eda",
   "metadata": {},
   "source": ["## 4ï¸âƒ£ Exploratory Data Analysis (EDA)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk['InvoiceDate'] = pd.to_datetime(df_uk['InvoiceDate'])\n",
    "df_uk['Month'] = df_uk['InvoiceDate'].dt.to_period('M').astype(str)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Monthly transaction volume\n",
    "monthly = df_uk.groupby('Month').size()\n",
    "monthly.plot(ax=axes[0], kind='bar', color='steelblue')\n",
    "axes[0].set_title('Monthly Transaction Volume (UK)')\n",
    "axes[0].set_ylabel('Transactions')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Price distribution\n",
    "df_uk['Price'].clip(0, 50).plot(ax=axes[1], kind='hist', bins=50, color='coral')\n",
    "axes[1].set_title('Unit Price Distribution (clipped at Â£50)')\n",
    "axes[1].set_xlabel('Price (Â£)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Hour of purchase\n",
    "df_uk['InvoiceDate'].dt.hour.value_counts().sort_index().plot(\n",
    "    ax=axes[0], kind='bar', color='mediumpurple')\n",
    "axes[0].set_title('Purchases by Hour of Day')\n",
    "axes[0].set_xlabel('Hour')\n",
    "\n",
    "# Top customers\n",
    "top_customers = df_uk.groupby('Customer ID')['Price'].sum().nlargest(10)\n",
    "top_customers.plot(ax=axes[1], kind='barh', color='teal')\n",
    "axes[1].set_title('Top 10 Customers by Revenue')\n",
    "axes[1].set_xlabel('Total Revenue (Â£)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-features",
   "metadata": {},
   "source": ["## 5ï¸âƒ£ Feature Engineering & Target Creation"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk['TotalPrice']    = df_uk['Quantity'] * df_uk['Price']\n",
    "df_uk['InvoiceHour']   = df_uk['InvoiceDate'].dt.hour\n",
    "df_uk['InvoiceDay']    = df_uk['InvoiceDate'].dt.day\n",
    "df_uk['InvoiceMonth']  = df_uk['InvoiceDate'].dt.to_period('M')\n",
    "\n",
    "print('New features added: TotalPrice, InvoiceHour, InvoiceDay, InvoiceMonth')\n",
    "df_uk[['Quantity','Price','TotalPrice','InvoiceHour','InvoiceDay']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate per customer per month\n",
    "customer_months = (\n",
    "    df_uk.groupby(['Customer ID', 'InvoiceMonth'])\n",
    "    .agg(\n",
    "        Quantity   = ('Quantity',    'sum'),\n",
    "        UnitPrice  = ('Price',       'mean'),\n",
    "        TotalPrice = ('TotalPrice',  'sum'),\n",
    "        InvoiceHour= ('InvoiceHour', 'mean'),\n",
    "        InvoiceDay = ('InvoiceDay',  'mean'),\n",
    "    ).reset_index()\n",
    ")\n",
    "customer_months['InvoiceMonth'] = customer_months['InvoiceMonth'].astype(str)\n",
    "customer_months.sort_values(['Customer ID', 'InvoiceMonth'], inplace=True)\n",
    "\n",
    "# Build lookup set of active (customer, month) pairs\n",
    "active_set = set(zip(customer_months['Customer ID'], customer_months['InvoiceMonth']))\n",
    "\n",
    "def next_month_str(period_str):\n",
    "    return str(pd.Period(period_str, freq='M') + 1)\n",
    "\n",
    "customer_months['NextMonth'] = customer_months['InvoiceMonth'].apply(next_month_str)\n",
    "\n",
    "customer_months['WillBuyNextMonth'] = customer_months.apply(\n",
    "    lambda r: 1 if (r['Customer ID'], r['NextMonth']) in active_set else 0, axis=1\n",
    ")\n",
    "\n",
    "print('Target distribution:')\n",
    "print(customer_months['WillBuyNextMonth'].value_counts())\n",
    "print(f'\\nClass balance: {customer_months[\"WillBuyNextMonth\"].mean():.1%} positive')\n",
    "customer_months.head()"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-split",
   "metadata": {},
   "source": ["## 6ï¸âƒ£ Train / Test Split"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = ['Quantity', 'UnitPrice', 'TotalPrice', 'InvoiceHour', 'InvoiceDay']\n",
    "TARGET_COL   = 'WillBuyNextMonth'\n",
    "\n",
    "model_df = customer_months[FEATURE_COLS + [TARGET_COL]].dropna()\n",
    "\n",
    "X = model_df[FEATURE_COLS]\n",
    "y = model_df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')\n",
    "\n",
    "# Save splits\n",
    "os.makedirs('data', exist_ok=True)\n",
    "train_df = X_train.copy(); train_df[TARGET_COL] = y_train.values\n",
    "test_df  = X_test.copy();  test_df[TARGET_COL]  = y_test.values\n",
    "train_df.to_csv('data/train.csv', index=False)\n",
    "test_df.to_csv('data/test.csv',   index=False)\n",
    "print('Saved train.csv and test.csv âœ…')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-train",
   "metadata": {},
   "source": ["## 7ï¸âƒ£ Model Training â€” XGBoost"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators     = 100,\n",
    "    max_depth        = 5,\n",
    "    learning_rate    = 0.1,\n",
    "    random_state     = RANDOM_STATE,\n",
    "    eval_metric      = 'logloss',\n",
    "    use_label_encoder= False,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "print('Training complete âœ…')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-eval",
   "metadata": {},
   "source": ["## 8ï¸âƒ£ Model Evaluation"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy' : accuracy_score(y_test, y_pred),\n",
    "    'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "    'Recall'   : recall_score(y_test, y_pred, zero_division=0),\n",
    "    'F1-Score' : f1_score(y_test, y_pred, zero_division=0),\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "print('=== Evaluation Metrics ===')\n",
    "display(metrics_df.style.format('{:.4f}'))\n",
    "\n",
    "print('\\n=== Classification Report ===')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-cm",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['Not Buy', 'Will Buy'])\n",
    "disp.plot(ax=axes[0], colorbar=False, cmap='Blues')\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "\n",
    "# Feature importance\n",
    "importances = model.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=FEATURE_COLS).sort_values()\n",
    "feat_imp.plot(kind='barh', ax=axes[1], color='steelblue')\n",
    "axes[1].set_title('XGBoost Feature Importance')\n",
    "axes[1].set_xlabel('Importance Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-cv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
    "print(f'5-Fold Cross Validation F1 Scores: {cv_scores.round(4)}')\n",
    "print(f'Mean F1: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-save",
   "metadata": {},
   "source": ["## 9ï¸âƒ£ Save Model"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "MODEL_PATH = 'models/xgb_model.pkl'\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "print(f'Model saved â†’ {MODEL_PATH} âœ…')\n",
    "\n",
    "# Verify reload\n",
    "loaded_model = joblib.load(MODEL_PATH)\n",
    "test_pred    = loaded_model.predict(X_test[:3])\n",
    "print(f'Reload check â€” sample predictions: {test_pred}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-drift",
   "metadata": {},
   "source": ["## ðŸ”Ÿ Drift Monitoring Simulation (MLOps Level 2)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-drift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Baseline predictions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "original_preds = model.predict(X_test)\n",
    "\n",
    "# â”€â”€ Simulate drift: Quantity Ã—1.2, UnitPrice Ã—0.8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_drifted = X_test.copy()\n",
    "X_drifted['Quantity']   = X_drifted['Quantity']  * 1.2\n",
    "X_drifted['UnitPrice']  = X_drifted['UnitPrice'] * 0.8\n",
    "X_drifted['TotalPrice'] = X_drifted['Quantity']  * X_drifted['UnitPrice']\n",
    "\n",
    "drifted_preds = model.predict(X_drifted)\n",
    "\n",
    "# â”€â”€ Compute prediction change â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_changed   = np.sum(original_preds != drifted_preds)\n",
    "pct_changed = (n_changed / len(original_preds)) * 100\n",
    "\n",
    "print(f'Total samples           : {len(original_preds):,}')\n",
    "print(f'Predictions changed     : {n_changed:,}')\n",
    "print(f'Prediction change %     : {pct_changed:.2f}%')\n",
    "print()\n",
    "\n",
    "DRIFT_THRESHOLD = 10.0\n",
    "if pct_changed > DRIFT_THRESHOLD:\n",
    "    print(f'âš ï¸  DRIFT DETECTED  ({pct_changed:.2f}% > {DRIFT_THRESHOLD}% threshold)')\n",
    "    print('    â†’ Recommend retraining with fresh data')\n",
    "else:\n",
    "    print(f'âœ…  No significant drift ({pct_changed:.2f}% â‰¤ {DRIFT_THRESHOLD}% threshold)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-drift-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise distribution shift\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "features_to_plot = ['Quantity', 'UnitPrice', 'TotalPrice']\n",
    "\n",
    "for ax, col in zip(axes, features_to_plot):\n",
    "    ax.hist(X_test[col], bins=40, alpha=0.6, label='Original', color='steelblue')\n",
    "    ax.hist(X_drifted[col], bins=40, alpha=0.6, label='Drifted',  color='coral')\n",
    "    ax.set_title(f'{col} Distribution')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Feature Distribution: Original vs Drifted', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-drift-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Feature'         : FEATURE_COLS,\n",
    "    'Original Mean'   : X_test[FEATURE_COLS].mean().values.round(4),\n",
    "    'Drifted Mean'    : X_drifted[FEATURE_COLS].mean().values.round(4),\n",
    "})\n",
    "summary['Î”%'] = (\n",
    "    abs(summary['Drifted Mean'] - summary['Original Mean'])\n",
    "    / (summary['Original Mean'] + 1e-9) * 100\n",
    ").round(2)\n",
    "\n",
    "print('=== Feature Drift Summary ===')\n",
    "display(summary)\n",
    "\n",
    "print(f'\\n=== Final Drift Report ===')\n",
    "print(f'Prediction Change : {pct_changed:.2f}%')\n",
    "print('Status            : ' + ('âš ï¸ DRIFT DETECTED' if pct_changed > DRIFT_THRESHOLD else 'âœ… OK'))"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": [
    "## âœ… Project Summary\n",
    "\n",
    "| Component         | Status | Details |\n",
    "|-------------------|--------|---------|\n",
    "| Data Preprocessing| âœ…     | UK filter, null drops, feature engineering |\n",
    "| Feature Engineering| âœ…    | TotalPrice, InvoiceHour, InvoiceDay |\n",
    "| Target Creation   | âœ…     | Next-month purchase flag |\n",
    "| Model Training    | âœ…     | XGBoost (100 trees, depth 5) |\n",
    "| Evaluation        | âœ…     | Accuracy, Precision, Recall, F1 |\n",
    "| Model Persistence | âœ…     | xgb_model.pkl via joblib |\n",
    "| Streamlit UI      | âœ…     | Single + batch prediction |\n",
    "| Drift Monitoring  | âœ…     | Simulated drift, threshold alert |\n",
    "| MLOps Level       | âœ…     | Level 0 â†’ 2 coverage |\n",
    "\n",
    "```\n",
    "streamlit run app.py\n",
    "```"
   ]
  }

 ]
}
